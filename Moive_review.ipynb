{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec14aacd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (3.7.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from spacy) (63.4.1)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from spacy) (0.3.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from spacy) (1.10.4)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from spacy) (4.64.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from spacy) (2.11.3)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from spacy) (1.21.5)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from spacy) (5.2.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from spacy) (1.0.10)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from spacy) (21.3)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from spacy) (8.2.1)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from spacy) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from spacy) (2.4.8)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from spacy) (0.9.0)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from spacy) (2.28.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy) (3.0.9)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.8.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.9.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from thinc<8.3.0,>=8.1.8->spacy) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from thinc<8.3.0,>=8.1.8->spacy) (0.1.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy) (8.0.4)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from weasel<0.4.0,>=0.1.0->spacy) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from jinja2->spacy) (2.0.1)\n",
      "Requirement already satisfied: spacy in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (3.7.2)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from spacy) (8.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from spacy) (2.11.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from spacy) (1.10.4)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from spacy) (1.0.10)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from spacy) (4.64.1)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from spacy) (5.2.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from spacy) (63.4.1)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from spacy) (0.3.3)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from spacy) (0.9.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from spacy) (1.21.5)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from spacy) (2.4.8)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from spacy) (21.3)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from spacy) (2.28.1)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from spacy) (1.1.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy) (3.0.9)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.8.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.9.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from thinc<8.3.0,>=8.1.8->spacy) (0.1.3)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from thinc<8.3.0,>=8.1.8->spacy) (0.7.11)\n",
      "Requirement already satisfied: colorama in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy) (8.0.4)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from weasel<0.4.0,>=0.1.0->spacy) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from jinja2->spacy) (2.0.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gradio in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (3.50.2)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from gradio) (4.8.0)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from gradio) (1.4.4)\n",
      "Requirement already satisfied: jinja2<4.0 in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from gradio) (2.11.3)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from gradio) (6.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from gradio) (21.3)\n",
      "Requirement already satisfied: markupsafe~=2.0 in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from gradio) (2.0.1)\n",
      "Requirement already satisfied: httpx in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from gradio) (0.25.0)\n",
      "Requirement already satisfied: requests~=2.0 in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from gradio) (2.28.1)\n",
      "Requirement already satisfied: python-multipart in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from gradio) (0.0.6)\n",
      "Requirement already satisfied: pydub in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: fastapi in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from gradio) (0.104.0)\n",
      "Requirement already satisfied: matplotlib~=3.0 in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from gradio) (3.5.2)\n",
      "Requirement already satisfied: numpy~=1.0 in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from gradio) (1.21.5)\n",
      "Requirement already satisfied: semantic-version~=2.0 in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from gradio) (2.10.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.14.0 in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from gradio) (0.18.0)\n",
      "Requirement already satisfied: pillow<11.0,>=8.0 in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from gradio) (9.2.0)\n",
      "Requirement already satisfied: importlib-resources<7.0,>=1.3 in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from gradio) (6.0.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4 in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from gradio) (1.10.4)\n",
      "Requirement already satisfied: websockets<12.0,>=10.0 in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from gradio) (11.0.3)\n",
      "Requirement already satisfied: ffmpy in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from gradio) (0.3.1)\n",
      "Requirement already satisfied: gradio-client==0.6.1 in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from gradio) (0.6.1)\n",
      "Requirement already satisfied: orjson~=3.0 in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from gradio) (3.9.10)\n",
      "Requirement already satisfied: altair<6.0,>=4.2.0 in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from gradio) (5.0.1)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from gradio) (0.23.2)\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from gradio) (23.2.1)\n",
      "Requirement already satisfied: fsspec in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from gradio-client==0.6.1->gradio) (2023.10.0)\n",
      "Requirement already satisfied: toolz in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from altair<6.0,>=4.2.0->gradio) (0.11.2)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from altair<6.0,>=4.2.0->gradio) (4.16.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.14.0->gradio) (3.6.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.14.0->gradio) (4.64.1)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from importlib-resources<7.0,>=1.3->gradio) (3.8.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from matplotlib~=3.0->gradio) (0.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from matplotlib~=3.0->gradio) (3.0.9)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from matplotlib~=3.0->gradio) (1.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from matplotlib~=3.0->gradio) (4.25.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2022.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from requests~=2.0->gradio) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from requests~=2.0->gradio) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from requests~=2.0->gradio) (2022.9.14)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from requests~=2.0->gradio) (1.26.11)\n",
      "Requirement already satisfied: h11>=0.8 in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from uvicorn>=0.14.0->gradio) (0.14.0)\n",
      "Requirement already satisfied: click>=7.0 in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from uvicorn>=0.14.0->gradio) (8.0.4)\n",
      "Requirement already satisfied: anyio<4.0.0,>=3.7.1 in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from fastapi->gradio) (3.7.1)\n",
      "Requirement already satisfied: starlette<0.28.0,>=0.27.0 in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from fastapi->gradio) (0.27.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from httpx->gradio) (1.2.0)\n",
      "Requirement already satisfied: httpcore<0.19.0,>=0.18.0 in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from httpx->gradio) (0.18.0)\n",
      "Requirement already satisfied: exceptiongroup in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from anyio<4.0.0,>=3.7.1->fastapi->gradio) (1.1.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from click>=7.0->uvicorn>=0.14.0->gradio) (0.4.6)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (21.4.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.18.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Abuoden\\anaconda3\\lib\\runpy.py\", line 188, in _run_module_as_main\n",
      "    mod_name, mod_spec, code = _get_module_details(mod_name, _Error)\n",
      "  File \"C:\\Users\\Abuoden\\anaconda3\\lib\\runpy.py\", line 147, in _get_module_details\n",
      "    return _get_module_details(pkg_main_name, error)\n",
      "  File \"C:\\Users\\Abuoden\\anaconda3\\lib\\runpy.py\", line 111, in _get_module_details\n",
      "    __import__(pkg_name)\n",
      "  File \"C:\\Users\\Abuoden\\anaconda3\\lib\\site-packages\\spacy\\__init__.py\", line 13, in <module>\n",
      "    from . import pipeline  # noqa: F401\n",
      "  File \"C:\\Users\\Abuoden\\anaconda3\\lib\\site-packages\\spacy\\pipeline\\__init__.py\", line 1, in <module>\n",
      "    from .attributeruler import AttributeRuler\n",
      "  File \"C:\\Users\\Abuoden\\anaconda3\\lib\\site-packages\\spacy\\pipeline\\attributeruler.py\", line 8, in <module>\n",
      "    from ..language import Language\n",
      "  File \"C:\\Users\\Abuoden\\anaconda3\\lib\\site-packages\\spacy\\language.py\", line 43, in <module>\n",
      "    from .pipe_analysis import analyze_pipes, print_pipe_analysis, validate_attrs\n",
      "  File \"C:\\Users\\Abuoden\\anaconda3\\lib\\site-packages\\spacy\\pipe_analysis.py\", line 6, in <module>\n",
      "    from .tokens import Doc, Span, Token\n",
      "  File \"C:\\Users\\Abuoden\\anaconda3\\lib\\site-packages\\spacy\\tokens\\__init__.py\", line 1, in <module>\n",
      "    from ._serialize import DocBin\n",
      "  File \"C:\\Users\\Abuoden\\anaconda3\\lib\\site-packages\\spacy\\tokens\\_serialize.py\", line 14, in <module>\n",
      "    from ..vocab import Vocab\n",
      "  File \"spacy\\vocab.pyx\", line 1, in init spacy.vocab\n",
      "  File \"spacy\\tokens\\doc.pyx\", line 49, in init spacy.tokens.doc\n",
      "  File \"C:\\Users\\Abuoden\\anaconda3\\lib\\site-packages\\spacy\\schemas.py\", line 287, in <module>\n",
      "    class TokenPattern(BaseModel):\n",
      "  File \"pydantic\\main.py\", line 198, in pydantic.main.ModelMetaclass.__new__\n",
      "  File \"pydantic\\fields.py\", line 506, in pydantic.fields.ModelField.infer\n",
      "  File \"pydantic\\fields.py\", line 436, in pydantic.fields.ModelField.__init__\n",
      "  File \"pydantic\\fields.py\", line 552, in pydantic.fields.ModelField.prepare\n",
      "  File \"pydantic\\fields.py\", line 661, in pydantic.fields.ModelField._type_analysis\n",
      "  File \"pydantic\\fields.py\", line 668, in pydantic.fields.ModelField._type_analysis\n",
      "  File \"C:\\Users\\Abuoden\\anaconda3\\lib\\typing.py\", line 852, in __subclasscheck__\n",
      "    return issubclass(cls, self.__origin__)\n",
      "TypeError: issubclass() arg 1 must be a class\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wordcloud in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (1.9.2)\n",
      "Requirement already satisfied: pillow in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from wordcloud) (9.2.0)\n",
      "Requirement already satisfied: numpy>=1.6.1 in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from wordcloud) (1.21.5)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from wordcloud) (3.5.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (3.0.9)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (0.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (2.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (21.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (1.4.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (4.25.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\abuoden\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->wordcloud) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy\n",
    "!pip install -U spacy\n",
    "!pip install gradio\n",
    "!python -m spacy download en_core_web_sm\n",
    "!pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ab5556a",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "issubclass() arg 1 must be a class",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13196\\2553137947.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mspacy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstring\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\spacy\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mthinc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mConfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprefer_gpu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequire_cpu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequire_gpu\u001b[0m  \u001b[1;31m# noqa: F401\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpipeline\u001b[0m  \u001b[1;31m# noqa: F401\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mutil\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mabout\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m__version__\u001b[0m  \u001b[1;31m# noqa: F401\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\spacy\\pipeline\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mattributeruler\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAttributeRuler\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mdep_parser\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDependencyParser\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0medit_tree_lemmatizer\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mEditTreeLemmatizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mentity_linker\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mEntityLinker\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mentityruler\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mEntityRuler\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\spacy\\pipeline\\attributeruler.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mutil\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mErrors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlanguage\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLanguage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatcher\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMatcher\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscorer\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mScorer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\spacy\\language.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mlang\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenizer_exceptions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBASE_EXCEPTIONS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mURL_MATCH\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mlookups\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mload_lookups\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mpipe_analysis\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0manalyze_pipes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprint_pipe_analysis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidate_attrs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m from .schemas import (\n\u001b[0;32m     45\u001b[0m     \u001b[0mConfigSchema\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\spacy\\pipe_analysis.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mErrors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mtokens\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDoc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSpan\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mToken\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdot_to_dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\spacy\\tokens\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_serialize\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDocBin\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mdoc\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDoc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mmorphanalysis\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMorphAnalysis\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mspan\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSpan\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mspan_group\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSpanGroup\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\spacy\\tokens\\_serialize.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mErrors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSimpleFrozenList\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_path\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mVocab\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_dict_proxies\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSpanGroups\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mdoc\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDOCBIN_ALL_ATTRS\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mALL_ATTRS\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\spacy\\vocab.pyx\u001b[0m in \u001b[0;36minit spacy.vocab\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\spacy\\tokens\\doc.pyx\u001b[0m in \u001b[0;36minit spacy.tokens.doc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\spacy\\schemas.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    285\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    286\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 287\u001b[1;33m \u001b[1;32mclass\u001b[0m \u001b[0mTokenPattern\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseModel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    288\u001b[0m     \u001b[0morth\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mStringValue\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    289\u001b[0m     \u001b[0mtext\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mStringValue\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pydantic\\main.cp39-win_amd64.pyd\u001b[0m in \u001b[0;36mpydantic.main.ModelMetaclass.__new__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pydantic\\fields.cp39-win_amd64.pyd\u001b[0m in \u001b[0;36mpydantic.fields.ModelField.infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pydantic\\fields.cp39-win_amd64.pyd\u001b[0m in \u001b[0;36mpydantic.fields.ModelField.__init__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pydantic\\fields.cp39-win_amd64.pyd\u001b[0m in \u001b[0;36mpydantic.fields.ModelField.prepare\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pydantic\\fields.cp39-win_amd64.pyd\u001b[0m in \u001b[0;36mpydantic.fields.ModelField._type_analysis\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pydantic\\fields.cp39-win_amd64.pyd\u001b[0m in \u001b[0;36mpydantic.fields.ModelField._type_analysis\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\typing.py\u001b[0m in \u001b[0;36m__subclasscheck__\u001b[1;34m(self, cls)\u001b[0m\n\u001b[0;32m    850\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0missubclass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__origin__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__origin__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    851\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_GenericAlias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 852\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0missubclass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__origin__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    853\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__subclasscheck__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: issubclass() arg 1 must be a class"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import spacy\n",
    "import string\n",
    "import pickle\n",
    "import os\n",
    "import shutil\n",
    "from wordcloud import WordCloud\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from spacy.lang.en import English\n",
    "from scipy.stats import ttest_ind\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.base import TransformerMixin \n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6defc181",
   "metadata": {},
   "source": [
    "## Data Collection & Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607bd18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('C:Assets\\Train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb39008",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac46e650",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c566ba90",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb88722",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0feb5e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57d3923",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Columns Names: {list(data.columns)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfc9701",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1=pd.read_csv('C:Assets\\Test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799fa249",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72dd3eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016b8792",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.rename(columns={'content': 'review'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82bf6675",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop('review_file', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4703645",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d29b2f",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013ede5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of sentiment labels\n",
    "sns.countplot(x='sentiment', data=data)\n",
    "plt.title('Distribution of Sentiment Labels')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a134b711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of each sentiment label\n",
    "sentiment_count = data['sentiment'].value_counts()\n",
    "\n",
    "print(sentiment_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f93401",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88796978",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2ae4e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "24c12965",
   "metadata": {},
   "source": [
    "## HYPOTHESIS TESTING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349ff0ce",
   "metadata": {},
   "source": [
    "### Question: Is there a significant difference in the average word count between positive and negative reviews\n",
    "\n",
    "### H(0) - There is no significant difference in the average word count between positive and negative reviews \n",
    "\n",
    "### H(1)- There is a significant difference in the average word count between positive and negative reviews "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95ce0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate positive and negative reviews\n",
    "positive_reviews = data[data['sentiment'] == 'positive']\n",
    "negative_reviews = data[data['sentiment'] == 'negative']\n",
    "\n",
    "# Calculate word count for each review\n",
    "positive_reviews['word_count'] = positive_reviews['review'].apply(lambda x: len(x.split()))\n",
    "negative_reviews['word_count'] = negative_reviews['review'].apply(lambda x: len(x.split()))\n",
    "\n",
    "# Perform a two-sample t-test\n",
    "t_stat, p_value = ttest_ind(positive_reviews['word_count'], negative_reviews['word_count'])\n",
    "\n",
    "# Define the significance level (alpha)\n",
    "alpha = 0.05\n",
    "\n",
    "# Check the p-value\n",
    "if p_value < alpha:\n",
    "    print(\"Reject the null hypothesis: There is a significant difference in word count between positive and negative reviews.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: There is no significant difference in word count between positive and negative reviews.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6af6ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61511324",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0b4bc7ef",
   "metadata": {},
   "source": [
    "  ## ANSWERING QUESTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c173ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the distribution of sentiment labels\n",
    "sentiment_counts = data['sentiment'].value_counts()\n",
    "plt.bar(sentiment_counts.index, sentiment_counts.values)\n",
    "plt.title('Distribution of Sentiment Labels')\n",
    "plt.xlabel('Sentiment')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20fcb03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21961f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3813452",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5b00949c",
   "metadata": {},
   "source": [
    "## Feature Processing & Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c87ba04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load spaCy\n",
    "# nlp = spacy.load(\"en_core_web_sm\")\n",
    "nlp = English()\n",
    "stopwords = list(nlp.Defaults.stop_words)\n",
    "punctuations = string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7504cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the text before splitting\n",
    "data['review'] = data['review'].apply(lambda text: text.strip().lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db7ed71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization, stopwords removal, and punctuation removal using spaCy\n",
    "#def process_text(text):\n",
    "   # doc = nlp(text)\n",
    "    #tokens = [token.text for token in doc if token.text not in stopwords and token.text not in punctuations]\n",
    "    #return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c40b60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Additional stopwords and punctuations\n",
    "additional_stopwords = {\"film\", \"movie\"}  # Customize this list based on your data\n",
    "stopwords = list(STOP_WORDS.union(additional_stopwords))\n",
    "punctuations = string.punctuation\n",
    "\n",
    "# Function for processing text\n",
    "def process_text(text):\n",
    "    doc = nlp(text)\n",
    "    tokens = []\n",
    "    for token in doc:\n",
    "        if token.text.lower() not in stopwords and token.text not in punctuations:\n",
    "            if token.lemma_ == '-PRON-':  # Handle pronouns\n",
    "                tokens.append(token.text)\n",
    "            else:\n",
    "                tokens.append(token.lemma_)\n",
    "    # Handling negation\n",
    "    processed_tokens = []\n",
    "    is_negation = False\n",
    "    for token in tokens:\n",
    "        if token in [\"not\", \"no\", \"n't\", \"never\"]:\n",
    "            is_negation = not is_negation\n",
    "        else:\n",
    "            if is_negation and token in [\"good\", \"great\", \"excellent\"]:  # Adjust for positive words affected by negation\n",
    "                token = \"bad_\" + token\n",
    "            elif is_negation and token in [\"bad\", \"poor\", \"worst\"]:  # Adjust for negative words affected by negation\n",
    "                token = \"good_\" + token\n",
    "            processed_tokens.append(token)\n",
    "    return ' '.join(processed_tokens)\n",
    "\n",
    "# Apply the updated processing function to the 'review' column\n",
    "data['processed_review'] = data['review'].apply(process_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16e4a13",
   "metadata": {},
   "source": [
    "## Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8588b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X = data['review']\n",
    "y = data['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66cf5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d59d729",
   "metadata": {},
   "source": [
    "## Feature Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67b1f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  #Tokenization, stopwords removal, and punctuation removal using spaCy\n",
    "# def process_text(text):\n",
    "#     doc = nlp(text)\n",
    "#     tokens = [token.text for token in doc if token.text not in stopwords and token.text not in punctuations]\n",
    "#     return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a19b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.apply(process_text)\n",
    "X_test = X_test.apply(process_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb7df53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text vectorization using TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf134ed",
   "metadata": {},
   "source": [
    "## TRAIN & EVALUATE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7875e2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Train a sentiment classifier \n",
    "# classifier = MultinomialNB()\n",
    "# classifier.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# # Make predictions on the test set\n",
    "# y_pred = classifier.predict(X_test_tfidf)\n",
    "\n",
    "# # Print the classification report\n",
    "# class_report = classification_report(y_test, y_pred)\n",
    "# print(\"Classification Report:\")\n",
    "# print(class_report)\n",
    "\n",
    "# # Calculate and print the accuracy score\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "# print(f\"Accuracy Score: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36554201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of classifiers\n",
    "classifiers = {\n",
    "    \"MultinomialNB\": MultinomialNB(),\n",
    "    \"LogisticRegression\": LogisticRegression(),\n",
    "    \"RandomForest\": RandomForestClassifier()\n",
    "}\n",
    "\n",
    "# Train and evaluate each classifier\n",
    "for clf_name, classifier in classifiers.items():\n",
    "    classifier.fit(X_train_tfidf, y_train)\n",
    "    y_pred = classifier.predict(X_test_tfidf)\n",
    "\n",
    "    # Print the classification report\n",
    "    class_report = classification_report(y_test, y_pred)\n",
    "    print(f\"Classification Report for {clf_name}:\")\n",
    "    print(class_report)\n",
    "\n",
    "    # Calculate and print the accuracy score in percentage format\n",
    "    accuracy = accuracy_score(y_test, y_pred) * 100\n",
    "    print(f\"Accuracy Score for {clf_name}: {accuracy:.2f}%\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe849fb",
   "metadata": {},
   "source": [
    "## CONFUSION MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87beccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Train a sentiment classifier \n",
    "# classifier = MultinomialNB()\n",
    "# classifier.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# # Make predictions on the test set\n",
    "# y_pred = classifier.predict(X_test_tfidf)\n",
    "\n",
    "# # Calculate the confusion matrix\n",
    "# conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# # Print the confusion matrix\n",
    "# print(\"Confusion Matrix:\")\n",
    "# print(conf_matrix)\n",
    "\n",
    "# # Visualize the confusion matrix \n",
    "# plt.figure(figsize=(8, 6))\n",
    "# sns.heatmap(conf_matrix, annot=True, fmt='d', cmap=\"Blues\", xticklabels=['Negative', 'Positive'], yticklabels=['Negative', 'Positive'])\n",
    "# plt.xlabel('Predicted')\n",
    "# plt.ylabel('Actual')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f084d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "for clf_name, classifier in classifiers.items():\n",
    "    classifier.fit(X_train_tfidf, y_train)\n",
    "    y_pred = classifier.predict(X_test_tfidf)\n",
    "    \n",
    "    # Create the confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    # Print the confusion matrix distribution\n",
    "    print(f\"Confusion Matrix for {clf_name} Distribution:\")\n",
    "    print(pd.DataFrame(cm, index=['Actual Negative', 'Actual Positive'], columns=['Predicted Negative', 'Predicted Positive']))\n",
    "\n",
    "    # Plot the confusion matrix as a heatmap\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Negative', 'Positive'], yticklabels=['Negative', 'Positive'])\n",
    "    plt.title(f'Confusion Matrix for {clf_name}')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce4ed3e",
   "metadata": {},
   "source": [
    "## HYPERPARAMETER TUNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef39517c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100],  # Regularization strength\n",
    "    'penalty': ['l1', 'l2']  # Regularization type\n",
    "}\n",
    "\n",
    "# Create the logistic regression model with random state\n",
    "logistic_classifier = LogisticRegression(solver='liblinear', max_iter=1000, random_state=42)\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "grid_search = GridSearchCV(logistic_classifier, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Perform grid search\n",
    "grid_search.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "\n",
    "# Train the final model with the best hyperparameters\n",
    "best_classifier = LogisticRegression(solver='liblinear', max_iter=1000, **best_params)\n",
    "best_classifier.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c645e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Make predictions on the test set using the tuned model\n",
    "y_pred = best_classifier.predict(X_test_tfidf)\n",
    "\n",
    "# Calculate and print the accuracy score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy Score after Hyperparameter Tuning: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c412a8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to store the components and model\n",
    "components_dict = {\n",
    "    'cleaner': process_text,\n",
    "    'cleaner_tfidf_vectorizer': tfidf_vectorizer,\n",
    "    'cleaner_classifier': best_classifier\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ee0417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a folder to store the exported data\n",
    "folder_name = 'comp_folder'\n",
    "os.makedirs(folder_name, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fff7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the components and model\n",
    "components_path = os.path.join(folder_name, 'sentiment_components.pkl')\n",
    "with open(components_path, 'wb') as file:\n",
    "    pickle.dump(components_dict, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a765a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the requirements.txt file\n",
    "requirements_file = 'requirements.txt'\n",
    "os.system(f'pip freeze > {os.path.join(folder_name, requirements_file)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0615c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zip the exported data folder\n",
    "shutil.make_archive('exported_data', 'zip', 'exported_comp_folder')\n",
    "\n",
    "print(\"Exported data has been zipped.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba64acb",
   "metadata": {},
   "source": [
    "### Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a21fb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the exported components from the file\n",
    "components_path = 'comp_folder/sentiment_components.pkl'\n",
    "with open(components_path, 'rb') as file:\n",
    "    components_dict = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380f738f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the loaded components\n",
    "loaded_cleaner = components_dict['cleaner']\n",
    "loaded_vectorizer = components_dict['cleaner_tfidf_vectorizer']\n",
    "loaded_classifier = components_dict['cleaner_classifier']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6cb6095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the new data from a CSV file\n",
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256cd44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.rename(columns={'content': 'review'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176330b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = data1['review_file'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86daf75",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.drop('review_file', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e827faff",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1['review'] = data1['review'].apply(lambda text: text.strip().lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0aa00a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply text cleaning to the new data\n",
    "data1['review'] = data1['review'].apply(loaded_cleaner)\n",
    "\n",
    "# Vectorize the new data using the loaded vectorizer\n",
    "X_new_tfidf = loaded_vectorizer.transform(data1['review'])\n",
    "\n",
    "# Make predictions on the new data\n",
    "new_predictions = loaded_classifier.predict(X_new_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4115707e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the \"review_file\" column back to the data1 DataFrame\n",
    "data1['review_file'] = files\n",
    "\n",
    "# Add the predictions to the new_data DataFrame\n",
    "data1['predicted_sentiment'] = new_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65e89a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame with only \"review_file\" and \"predicted_sentiment\" columns\n",
    "prediction = data1[['review_file', 'predicted_sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54831dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051aed01",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a498adfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the occurrences of \"Positive\" and \"Negative\" in the predictions\n",
    "count = prediction['predicted_sentiment'].value_counts()\n",
    "\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38249d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the Predictions\n",
    "prediction.to_csv('predicted_sentiment_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3faae0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip show spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2758d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import joblib\n",
    "import pickle\n",
    "# from text_preprocessing import process_text\n",
    "\n",
    "\n",
    "# Load the exported components\n",
    "components_path = r'src\\assets\\ML\\sentiment_components.pkl'\n",
    "with open(components_path, 'rb') as file:\n",
    "    components_dict = pickle.load(file)\n",
    "\n",
    "\n",
    "loaded_cleaner = components_dict['cleaner']\n",
    "loaded_vectorizer = components_dict['cleaner_tfidf_vectorizer']\n",
    "loaded_classifier = components_dict['cleaner_classifier']\n",
    "\n",
    "def sent_analysis(text):\n",
    "    # Preprocess the input text using the loaded cleaner\n",
    "    text = loaded_cleaner(text)\n",
    "    \n",
    "    # Vectorize the text using the loaded vectorizer\n",
    "    X_tfidf = loaded_vectorizer.transform([text])\n",
    "    \n",
    "    # Make predictions using the loaded classifier\n",
    "    prediction = loaded_classifier.predict(X_tfidf)[0]\n",
    "    \n",
    "    # Return the predicted sentiment label\n",
    "    return prediction\n",
    "\n",
    "# Create a Gradio interface\n",
    "demo = gr.Interface(\n",
    "    fn=sent_analysis,\n",
    "    inputs=gr.Textbox(placeholder=\"Enter a movie review...\"),\n",
    "    outputs=\"label\",\n",
    "    interpretation=\"default\",\n",
    "    examples=[\n",
    "        [\"I loved the movie! It was fantastic.\"],\n",
    "        [\"The acting was terrible, and the plot was boring.\"],\n",
    "        [\"This film is just okay. Not great, not terrible.\"],\n",
    "    ],\n",
    "    title=\"Movie Review Sentiment Analysis\",\n",
    "    description=\"An AI model that predicts sentiment in movie reviews, providing labels for 'NEGATIVE' and 'POSITIVE' sentiments.\",\n",
    "    theme=\"default\",\n",
    "    live=True,\n",
    ")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demo.launch()\n",
    "    \n",
    "!python src/app.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabdd60f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
